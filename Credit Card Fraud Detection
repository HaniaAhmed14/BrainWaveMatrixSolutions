# Step 1
import pandas as pd

df = pd.read_csv(creditcard.csv')

print("First few rows of the dataset:")
print(df.head())

print("\nMissing values in the dataset:")
print(df.isnull().sum())

print("\nClass distribution (fraud vs non-fraud):")
print(df['Class'].value_counts(normalize=True))  # Display proportions of fraud vs non-fraud

from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

#Step 2
X = df.drop(columns=['Class'])
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train[['Time', 'Amount']] = scaler.fit_transform(X_train[['Time', 'Amount']])
X_test[['Time', 'Amount']] = scaler.transform(X_test[['Time', 'Amount']])  # Use the same scaler on test data

smote = SMOTE(sampling_strategy=0.5, random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Print new class distribution
print("Class distribution after SMOTE:")
print(pd.Series(y_train_resampled).value_counts(normalize=True))

# Training and testing shapes
print("\nTraining data shape:", X_train_resampled.shape)
print("Testing data shape:", X_test.shape)

# Step 4

from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
import xgboost as xgb
from sklearn.metrics import classification_report, roc_auc_score

# models
models = {
    "Random Forest": RandomForestClassifier(random_state=42, class_weight='balanced'),
    "XGBoost": xgb.XGBClassifier(random_state=42, scale_pos_weight=3),  # Adjust scale_pos_weight for imbalance
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Neural Network": MLPClassifier(random_state=42, max_iter=1000)
    }

# Evaluating the models
for model_name, model in models.items():
    print(f"\nTraining {model_name}...")

    # Train the model
    model.fit(X_train, y_train)

    # Predict on the test set
    y_pred = model.predict(X_test)

    print(f"\n{model_name} Classification Report:")
    print(classification_report(y_test, y_pred))

    # ROC-AUC Score
    y_prob = model.predict_proba(X_test)[:, 1]  # Probability scores for positive class (fraud)
    print(f"ROC-AUC Score for {model_name}: {roc_auc_score(y_test, y_prob)}")

#Step 5
import xgboost as xgb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score
import numpy as np

xgb_model = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False)

#cross-validation strategy (StratifiedKFold)
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

#store ROC-AUC scores
roc_auc_scores = []

#cross-validation
for train_index, test_index in kf.split(X_train_resampled, y_train_resampled):
    # Use .iloc to correctly index the DataFrame
    X_train_fold, X_test_fold = X_train_resampled.iloc[train_index], X_train_resampled.iloc[test_index]
    y_train_fold, y_test_fold = y_train_resampled.iloc[train_index], y_train_resampled.iloc[test_index]
# Train the model   
    xgb_model.fit(X_train_fold, y_train_fold)

# Probabilities for ROC-AUC calculation
    y_pred_prob = xgb_model.predict_proba(X_test_fold)[:, 1]

# Calculate ROC-AUC score
    auc_score = roc_auc_score(y_test_fold, y_pred_prob)
    roc_auc_scores.append(auc_score)

# Display the average ROC-AUC score across all folds
print(f'Average ROC-AUC score across all folds: {np.mean(roc_auc_scores)}')

# Step 6

import matplotlib.pyplot as plt
import xgboost as xgb

# Plotting feature importance
xgb.plot_importance(xgb_model)
plt.show()

import shap
# SHAP values
explainer = shap.Explainer(xgb_model)
shap_values = explainer(X_test)

# SHAP summary plot
shap.summary_plot(shap_values, X_test)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Non-Fraud', 'Fraud'])
disp.plot(cmap='Blues')
plt.show()

#Step 7
from sklearn.cluster import KMeans
import numpy as np

# Train KMeans model
kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(X_train_resampled)

# Predict the closest cluster for each point in the test set
y_pred_kmeans = kmeans.predict(X_test)

# Compute the distances to the cluster centers for anomaly detection
distances = np.min(kmeans.transform(X_test), axis=1)

# Define a threshold (e.g., 90th percentile of the distances) to classify anomalies
threshold = np.percentile(distances, 90)

# Classify points as anomalies if their distance is above the threshold
y_pred_kmeans = [1 if dist > threshold else 0 for dist in distances]

# Classification report
print("KMeans Anomaly Detection Classification Report:")
print(classification_report(y_test, y_pred_kmeans))

# Confusion Matrix
conf_matrix_kmeans = confusion_matrix(y_test, y_pred_kmeans)
print("\nConfusion Matrix:")
print(conf_matrix_kmeans)

# ROC-AUC Score
roc_auc_kmeans = roc_auc_score(y_test, y_pred_kmeans)
print("\nROC-AUC Score for KMeans:", roc_auc_kmeans)
